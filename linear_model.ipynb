{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MyLineReg():\n",
    "    def __init__(self, n_iter, learning_rate, metric=None, reg=None, l1_coef=0, l2_coef=0):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = self.learning_rate_type(learning_rate)\n",
    "        self.weights = None\n",
    "        self.metric = metric\n",
    "        self.metrics()\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        \n",
    "\n",
    "    def calculate_gradient(self, X, y, y_pred):\n",
    "        if self.reg == 'l1':\n",
    "            return (2/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l1_coef*np.sign(self.weights)\n",
    "        if self.reg == 'l2':\n",
    "            return (2/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l2_coef*2*(self.weights)\n",
    "        if self.reg == 'elasticnet':\n",
    "            assert self.l1_coef != 0 and self.l2_coef != 0 \n",
    "            return (2/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l1_coef*np.sign(self.weights) + self.l2_coef*2*(self.weights)\n",
    "        else:\n",
    "            return (2/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X)\n",
    "\n",
    "    def learning_rate_type(self, LR):\n",
    "        if not isinstance(LR, float):\n",
    "            return LR\n",
    "        else:\n",
    "            return lambda x: LR\n",
    "\n",
    "    def metrics(self) -> None:\n",
    "        if self.metric:\n",
    "            if self.metric == 'mae':\n",
    "                self.metric = ['mae', lambda y,\n",
    "                               y_pred: np.mean(np.abs(y.values - y_pred))]\n",
    "\n",
    "            if self.metric == 'mse':\n",
    "                self.metric = ['mse', lambda y,\n",
    "                               y_pred: np.mean((y.values - y_pred)**2)]\n",
    "\n",
    "            if self.metric == 'rmse':\n",
    "                self.metric = ['rmse', lambda y, y_pred: (\n",
    "                    np.mean((y.values - y_pred)**2))**(0.5)]\n",
    "\n",
    "            if self.metric == 'mape':\n",
    "                self.metric = ['mape', lambda y, y_pred: 100 *\n",
    "                               np.mean(np.abs((y.values - y_pred)/y))]\n",
    "\n",
    "            if self.metric == 'r2':\n",
    "                self.metric = ['r2', lambda y, y_pred: (1 -\n",
    "                               (np.sum((y.values - y_pred)**2))/(np.sum((y.values - np.mean(y.values))**2)))]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "\n",
    "    def fit(self, samples: pd.DataFrame, y: pd.Series, verbose=False) -> None:\n",
    "\n",
    "        X = samples.copy()\n",
    "        X.insert(0, 'bias', pd.Series(1, index=range(X.shape[0])))\n",
    "\n",
    "        self.weights = np.ones(X.shape[1])\n",
    "        for iter in range(1, self.n_iter+1):\n",
    "            y_pred = np.dot(X, self.weights)\n",
    "            loss = np.mean((y_pred - y.values)**2)\n",
    "\n",
    "\n",
    "            grad = self.calculate_gradient(X, y, y_pred)\n",
    "\n",
    "\n",
    "            self.weights = self.weights - grad * self.learning_rate(iter)\n",
    "\n",
    "            if verbose and (iter % verbose) == 0 and self.metric is not None:\n",
    "                print(\n",
    "                    f'iter = {iter+1} ||| Loss = {loss} ||| {self.metric[0]} = {self.metric[1](y, y_pred)}')\n",
    "            elif verbose and (iter % verbose) == 0:\n",
    "                print(f'iter = {iter+1} ||| Loss = {loss}')\n",
    "            if self.metric:\n",
    "                self.final_metric = self.metric[1](y, np.dot(X, self.weights))\n",
    "\n",
    "    def predict(self, samples: pd.DataFrame) -> int:\n",
    "        \"\"\"\n",
    "        Принимает на вход  матрицу фичей в виде датафрейма пандаса.\n",
    "        Дополняет матрицу фичей единичным вектором (первый столбец).\n",
    "        Возвращает вектор предсказаний.\n",
    "        \"\"\"\n",
    "\n",
    "        X = samples.copy()\n",
    "        X.insert(0, 'bias', pd.Series(1, index=range(X.shape[0])))\n",
    "\n",
    "        return np.dot(X, self.weights)\n",
    "\n",
    "    def get_coef(self) -> list():\n",
    "        try:\n",
    "            assert self.weights is not None\n",
    "            return np.array(self.weights[1:])\n",
    "        except:\n",
    "            return 'fit before!'\n",
    "\n",
    "    def get_best_score(self) -> int:\n",
    "        return self.final_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(range(1000))\n",
    "y = (pd.DataFrame(list(range(1000)))*150)\n",
    "\n",
    "model = MyLineReg(50, lambda iter: 0.5 * (0.85 ** iter), 'r2', reg='l2', l2_coef=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y, 10)\n",
    "# model.get_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "qw = model.learning_rate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.425\n",
      "0.36124999999999996\n",
      "0.30706249999999996\n",
      "0.26100312499999995\n",
      "0.22185265624999997\n",
      "0.18857475781249997\n",
      "0.16028854414062496\n",
      "0.13624526251953123\n",
      "0.11580847314160153\n",
      "0.0984372021703613\n",
      "0.0836716218448071\n",
      "0.07112087856808604\n",
      "0.06045274678287313\n",
      "0.05138483476544216\n",
      "0.043677109550625835\n",
      "0.037125543118031956\n",
      "0.03155671165032716\n",
      "0.026823204902778088\n",
      "0.022799724167361375\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(q(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
