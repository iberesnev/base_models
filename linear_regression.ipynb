{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "class MyLineReg():\n",
    "    def __init__(self, n_iter, learning_rate, metric=None, reg=None, l1_coef=0, l2_coef=0, sgd_sample=None, random_state=42):\n",
    "        self.n_iter = n_iter\n",
    "        self.weights = None\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.random_state = random_state\n",
    "        self.sgd_sample = sgd_sample\n",
    "\n",
    "        self.learning_rate = self.learning_rate_type(learning_rate)\n",
    "        self.metric = self.metrics(self.metric)\n",
    "\n",
    "    def sgd_sample_size(self, sgd_sample_num, samples):\n",
    "        if isinstance(sgd_sample_num, float):\n",
    "            return int(samples.shape[0] * sgd_sample_num)\n",
    "        elif isinstance(sgd_sample_num, int):\n",
    "            return sgd_sample_num\n",
    "        else:\n",
    "            return samples.shape[0]\n",
    "\n",
    "    def calculate_gradient(self, X, y, y_pred):\n",
    "        if self.reg == 'l1':\n",
    "            assert self.l1_coef != 0\n",
    "            return (2/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l1_coef*np.sign(self.weights)\n",
    "        elif self.reg == 'l2':\n",
    "            assert self.l2_coef != 0\n",
    "            return (2/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l2_coef*2*(self.weights)\n",
    "        elif self.reg == 'elasticnet':\n",
    "            assert self.l1_coef != 0 and self.l2_coef != 0\n",
    "            return (2/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l1_coef*np.sign(self.weights) + self.l2_coef*2*(self.weights)\n",
    "        else:\n",
    "            return (2/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X)\n",
    "\n",
    "    def learning_rate_type(self, LR):\n",
    "        if not isinstance(LR, float):\n",
    "            return LR\n",
    "        else:\n",
    "            return lambda x: LR\n",
    "\n",
    "    def metrics(self, metric) -> None:\n",
    "        if metric:\n",
    "            if metric == 'mae':\n",
    "                metric = ['mae', lambda y,\n",
    "                          y_pred: np.mean(np.abs(y.values - y_pred))]\n",
    "\n",
    "            elif metric == 'mse':\n",
    "                metric = ['mse', lambda y,\n",
    "                          y_pred: np.mean((y.values - y_pred)**2)]\n",
    "\n",
    "            elif metric == 'rmse':\n",
    "                metric = ['rmse', lambda y, y_pred: (\n",
    "                    np.mean((y.values - y_pred)**2))**(0.5)]\n",
    "\n",
    "            elif metric == 'mape':\n",
    "                metric = ['mape', lambda y, y_pred: 100 *\n",
    "                          np.mean(np.abs((y.values - y_pred)/y))]\n",
    "\n",
    "            elif metric == 'r2':\n",
    "                metric = ['r2', lambda y, y_pred: (1 -\n",
    "                                                   (np.sum((y.values - y_pred)**2))/(np.sum((y.values - np.mean(y.values))**2)))]\n",
    "        return metric\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "\n",
    "    def fit(self, samples: pd.DataFrame, y: pd.Series, verbose=False) -> None:\n",
    "        random.seed(self.random_state)  # фиксируем рандом сид\n",
    "\n",
    "        sgd_sample_quantity = self.sgd_sample_size(self.sgd_sample, samples)\n",
    "        X = samples.copy()\n",
    "        X.insert(0, 'bias', pd.Series(1, index=X.index))\n",
    "\n",
    "        self.weights = np.ones(X.shape[1])\n",
    "\n",
    "        for iter in range(1, self.n_iter+1):\n",
    "            sample_rows_idx = random.sample(\n",
    "                range(X.shape[0]), sgd_sample_quantity)\n",
    "            X_mini_batch = X.iloc[sample_rows_idx]\n",
    "            y_mini_batch = y.iloc[sample_rows_idx]\n",
    "\n",
    "            y_pred = np.dot(X_mini_batch, self.weights)\n",
    "            # loss = np.mean((y_pred - y_mini_batch.values)**2)\n",
    "            loss = np.mean((np.dot(X, self.weights) - y.values)**2)\n",
    "            grad = self.calculate_gradient(X_mini_batch, y_mini_batch, y_pred)\n",
    "\n",
    "            self.weights = self.weights - grad * self.learning_rate(iter)\n",
    "\n",
    "            if verbose and (iter % verbose) == 0 and self.metric is not None:\n",
    "                print(\n",
    "                    f'iter = {iter} ||| Loss = {loss} ||| {self.metric[0]} = {self.metric[1](y, y_pred)}')\n",
    "            elif verbose and (iter % verbose) == 0:\n",
    "                print(f'iter = {iter} ||| Loss = {loss}')\n",
    "        if self.metric:\n",
    "            self.final_metric = self.metric[1](y, np.dot(X, self.weights))\n",
    "\n",
    "    def predict(self, samples: pd.DataFrame) -> int:\n",
    "        \"\"\"\n",
    "        Принимает на вход  матрицу фичей в виде датафрейма пандаса.\n",
    "        Дополняет матрицу фичей единичным вектором (первый столбец).\n",
    "        Возвращает вектор предсказаний.\n",
    "        \"\"\"\n",
    "\n",
    "        X = samples.copy()\n",
    "        X.insert(0, 'bias', pd.Series(1, index=range(X.shape[0])))\n",
    "\n",
    "        return np.dot(X, self.weights)\n",
    "\n",
    "    def get_coef(self) -> list():\n",
    "        try:\n",
    "            assert self.weights is not None\n",
    "            return np.array(self.weights[1:])\n",
    "        except:\n",
    "            return 'fit before!'\n",
    "\n",
    "    def get_best_score(self) -> int:\n",
    "        return self.final_metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
