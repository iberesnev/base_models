{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "class MyLogReg():\n",
    "    def __init__(self, n_iter, learning_rate, weights=None, metric=None, reg=None, l1_coef=0, l2_coef=0, sgd_sample=None, random_state=42):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.random_state = random_state\n",
    "        self.sgd_sample = sgd_sample\n",
    "\n",
    "        self.metric = self.metrics(metric)\n",
    "        self.learning_rate = self.learning_rate_type(learning_rate)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "\n",
    "    def calculate_gradient(self, X, y, y_pred):\n",
    "        if self.reg == 'l1':\n",
    "            assert self.l1_coef != 0\n",
    "            return (1/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l1_coef*np.sign(self.weights)\n",
    "        elif self.reg == 'l2':\n",
    "            assert self.l2_coef != 0\n",
    "            return (1/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l2_coef*2*(self.weights)\n",
    "        elif self.reg == 'elasticnet':\n",
    "            assert self.l1_coef != 0 and self.l2_coef != 0\n",
    "            return (1/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X) + self.l1_coef*np.sign(self.weights) + self.l2_coef*2*(self.weights)\n",
    "        else:\n",
    "            return (1/X.shape[0]) * np.dot((y_pred - y.values.ravel()), X)\n",
    "\n",
    "    def learning_rate_type(self, LR):\n",
    "        if not isinstance(LR, float):\n",
    "            return LR\n",
    "        else:\n",
    "            return lambda x: LR\n",
    "        \n",
    "    def sgd_sample_size(self, sgd_sample_num, samples):\n",
    "        if isinstance(sgd_sample_num, float):\n",
    "            return int(samples.shape[0] * sgd_sample_num)\n",
    "        elif isinstance(sgd_sample_num, int):\n",
    "            return sgd_sample_num\n",
    "        else:\n",
    "            return samples.shape[0]\n",
    "\n",
    "    def metrics(self, metric) -> None:\n",
    "        if metric:\n",
    "            if metric == 'accuracy':\n",
    "                metric = ['accuracy', lambda y, y_pred: (\n",
    "                    np.sum(y.values.ravel() == (y_pred > 0.5).ravel())) / len(y)]\n",
    "\n",
    "            elif metric == 'precision':\n",
    "                # TP / (TP + FP)\n",
    "                def precision_score_func(y, y_pred):\n",
    "                    y_pred_binary = (y_pred > 0.5).ravel()\n",
    "                    y_ravel = y.values.ravel()\n",
    "                    TP = np.sum((y_ravel == 1) & (y_pred_binary == 1))\n",
    "                    FP = np.sum((y_ravel == 0) & (y_pred_binary == 1))\n",
    "                    return TP/(TP+FP)\n",
    "\n",
    "                metric = ['precision', precision_score_func]\n",
    "\n",
    "            elif metric == 'recall':\n",
    "                # TP / (TP + FN)\n",
    "                def recall_score_func(y, y_pred):\n",
    "                    y_pred_binary = (y_pred > 0.5)\n",
    "                    y_ravel = y.values.ravel()\n",
    "                    TP = np.sum((y_ravel == 1) & (y_pred_binary == 1))\n",
    "                    FN = np.sum((y_ravel == 1) & (y_pred_binary == 0))\n",
    "                    return TP/(TP+FN)\n",
    "                \n",
    "                metric = ['recall', recall_score_func]\n",
    "\n",
    "            elif metric == 'f1':\n",
    "                # 2 * precision * recall / (precision + recall)\n",
    "                def f1_score_func(y, y_pred):\n",
    "                    y_pred_binary = (y_pred > 0.5)\n",
    "                    y_ravel = y.values.ravel()\n",
    "                    TP = np.sum((y_ravel == 1) & (y_pred_binary == 1))\n",
    "                    FP = np.sum((y_ravel == 0) & (y_pred_binary == 1))\n",
    "                    FN = np.sum((y_ravel == 1) & (y_pred_binary == 0))\n",
    "                    precision = TP/(TP+FP)\n",
    "                    recall = TP/(TP+FN)\n",
    "                    return 2 * precision * recall / (precision + recall)\n",
    "                \n",
    "                metric = ['f1', f1_score_func]\n",
    "\n",
    "\n",
    "            elif metric == 'roc_auc':\n",
    "                def auc_score_def(y, y_pred):\n",
    "                    data = np.concatenate(\n",
    "                        (y.to_numpy().reshape(-1, 1), np.round(y_pred.reshape(-1, 1), 10)), axis=1)\n",
    "                    data = data[data[:, 1].argsort()][::-1]\n",
    "\n",
    "                    pos_above_iter = 0\n",
    "\n",
    "                    for y, pred in data:\n",
    "                        if y == 0:\n",
    "                            if (data[data[:, 1] == pred]).shape[0] > 1:\n",
    "                                pos_above_iter += np.sum(\n",
    "                                    data[data[:, 1] > pred][:, 0], axis=0) / 2\n",
    "                            pos_above_iter += np.sum(\n",
    "                                data[data[:, 1] > pred][:, 0], axis=0)\n",
    "                    return pos_above_iter / (np.sum(data[:, 0] == 1) * np.sum(data[:, 0] == 0))\n",
    "\n",
    "                metric = ['roc_auc', auc_score_def]\n",
    "\n",
    "        return metric\n",
    "\n",
    "    def fit(self, samples: pd.DataFrame, y: pd.Series, verbose=False) -> None:\n",
    "        random.seed(self.random_state)  # фиксируем рандом сид\n",
    "\n",
    "        sgd_sample_quantity = self.sgd_sample_size(self.sgd_sample, samples)\n",
    "\n",
    "        X = samples.copy()\n",
    "        X.insert(0, 'bias', pd.Series(1, index=X.index))\n",
    "\n",
    "        self.weights = np.ones(X.shape[1])\n",
    "\n",
    "        for iter in range(1, self.n_iter+1):\n",
    "            sample_rows_idx = random.sample(\n",
    "                range(X.shape[0]), sgd_sample_quantity)\n",
    "            X_mini_batch = X.iloc[sample_rows_idx]\n",
    "            y_mini_batch = y.iloc[sample_rows_idx]\n",
    "\n",
    "            y_pred = np.array(1/(1 + np.exp(-np.dot(X_mini_batch, self.weights))))\n",
    "\n",
    "            y_pred_for_loss = np.array(1/(1 + np.exp(-np.dot(X, self.weights))))\n",
    "\n",
    "            loss = -np.mean(np.log(y_pred_for_loss+1e-100)*y.values.ravel() +\n",
    "                            np.log(1 - y_pred_for_loss+1e-100)*(1-y.values.ravel()))\n",
    "\n",
    "            # grad = (1/(X.shape[0]) * np.dot((y_pred - y.values.ravel()), X))\n",
    "            grad = self.calculate_gradient(X_mini_batch, y_mini_batch, y_pred)\n",
    "\n",
    "            self.weights = self.weights - grad * self.learning_rate(iter)\n",
    "            if verbose and (iter % verbose) == 0 and self.metric is not None:\n",
    "                print(\n",
    "                    f'iter = {iter+1} ||| Loss = {loss} ||| {self.metric[0]} = {self.metric[1](y, y_pred_for_loss)}')\n",
    "            elif verbose and (iter % verbose) == 0:\n",
    "                print(f'iter = {iter+1} ||| Loss = {loss}')\n",
    "        if self.metric:\n",
    "            self.final_metric = self.metric[1](y, np.array(\n",
    "                1/(1 + np.exp(-np.dot(X, self.weights)))))\n",
    "\n",
    "    def predict(self, samples):\n",
    "        X = samples.copy()\n",
    "        X.insert(0, 'bias', pd.Series(1, index=range(X.shape[0])))\n",
    "        return (np.array(1/(1 + np.exp(-np.dot(X, self.weights)))) > 0.5).astype(np.int8)\n",
    "\n",
    "    def predict_proba(self, samples):\n",
    "        X = samples.copy()\n",
    "        X.insert(0, 'bias', pd.Series(1, index=range(X.shape[0])))\n",
    "        return np.array(1/(1 + np.exp(-np.dot(X, self.weights))))\n",
    "\n",
    "    def get_coef(self) -> list():\n",
    "        try:\n",
    "            assert self.weights is not None\n",
    "            return np.array(self.weights[1:])\n",
    "        except:\n",
    "            return 'fit before!'\n",
    "\n",
    "    def get_best_score(self) -> int:\n",
    "        return self.final_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 11 ||| Loss = 35.631830863566286 ||| precision = 0.643979057591623\n",
      "iter = 21 ||| Loss = 16.181827325897686 ||| precision = 0.6911764705882353\n",
      "iter = 31 ||| Loss = 13.34606526399461 ||| precision = 0.7177033492822966\n",
      "iter = 41 ||| Loss = 12.627028679628506 ||| precision = 0.7142857142857143\n",
      "iter = 51 ||| Loss = 12.579146054146257 ||| precision = 0.7142857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = MyLogReg(50, lambda iter: 0.5 * (0.85 ** iter), metric='precision', sgd_sample=0.1, reg='elasticnet', l1_coef=0.1, l2_coef=0.1)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = pd.DataFrame(np.random.randint(-25, 25, (400, 100)))\n",
    "y = pd.DataFrame({'target': [0 if x<200 else 1 for x in range(400)]})\n",
    "\n",
    "x.fit(X, y, verbose=10)\n",
    "\n",
    "np.mean((x.predict_proba(X) > 0.5) == y.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
